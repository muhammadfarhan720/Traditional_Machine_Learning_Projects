# -*- coding: utf-8 -*-
"""ensemble model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d52O5XHp_99D8Z7Ne5J9lxPjhND6NfNX
"""

#ensemble model by Muhammad Farhan Azmine and Rubel Sarkar


import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
# importing utility modules
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import log_loss
# importing machine learning models for prediction
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression
# importing voting classifier
from sklearn.ensemble import VotingClassifier
import numpy as np
import pandas as pd
from sklearn.feature_selection import mutual_info_classif
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import SelectPercentile
from sklearn.datasets import make_classification
import numpy
import numpy as np
import csv
import warnings
from sklearn.metrics import plot_confusion_matrix
import seaborn as sns
import pandas as pd
import sklearn.tree as tree
import sklearn.impute as impute
import sklearn.model_selection as modelsel
import sklearn.metrics as metrics
from sklearn.neural_network import MLPRegressor
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import r2_score
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
import graphviz
from sklearn.model_selection import cross_val_score
import matplotlib.pylab as plt
import matplotlib.pyplot as plt
import pydotplus
import collections

#dirPath = '/Users/rubel/Documents/ECE5424/project/python_code/'
fileName = 'grouped_complete_MIT_new.xlsx'
#fileName = 'grouped_complete_Siena.xlsx'
filename_RT='grouped_complete_MIT_RT (1).xlsx'
"""
# MIT DataFrame
df = pd.read_excel(fileName, usecols=['T7-P7_variance', 't7-p7_dwtcavar', 'p7-o1_dwtcavar', 'f7-t7_dwtcarms',
                                                't7-p7_dwtcarms', 'F3-C3_ISI', 'C3-P3_ISI', 'P3-O1_ISI', 'CZ-PZ_ISI',
                                                'F7-T7_Theta', 'F7-T7_Alpha', 'T7-P7_Theta', 'T7-P7_Alpha',
                                                'P7-O1_Theta', 'P7-O1_Alpha', 'TempPar_Thetamed', 'TempPar_Thetamean',
                                                'TempPar_Alphamed', 'TempPar_Alphamean', 'CentPar_ISImed',
                                                'CentPar_ISImean', 'TempPar_dwtcArmsmed', 'TempPar_dwtcArmsmean',
                                                'TempPar_dwtcAvarmed', 'P8-O2_ZC','FP1-F7_ complexity','F4-C4_ZC',
                                                'F8-T8_ZC', 'p8-o2_dwtcdvar','fp1-f3_dwtcdent','f8-t8_dwtcdent',
                                                'T8-P8_ complexity','f3-c3_dwtcdent','fz-cz_dwtcdrms','FP2-F8_ZC',
                                                'p4-o2_dwtcaent','FrontTemp_variancemed','ParOcc_Betamed','ParOcc_Thetamed',
                                                'FrontTemp_variancemean','target'])
"""

# Siena DataFrame
df = pd.read_excel(filename_RT)

#df=df.rename(columns=str.upper)

df=df[['F7-T7_Delta', 'F7-T7_Theta', 'T7-P7_Delta', 'T7-P7_Theta',
                                                'P7-O1_Theta', 'f7-t7_dwtcavar', 't7-p7_dwtcavar', 'fp1-f7_dwtcarms',
                                                'f7-t7_dwtcarms', 't7-p7_dwtcarms', 'fp1-f3_dwtcarms', 'fz-cz_dwtcarms',
                                                'FrontTemp_Thetamed', 'FrontTemp_Thetamean', 'FrontTemp_dwtcArmsmed',
                                                'FrontTemp_dwtcArmsmean', 'FrontCent_dwtcArmsmed',
                                                'FrontTemp_dwtcAvarmed', 'FrontTemp_dwtcAvarmean',
                                                'TempPar_dwtcAvarmed', 'TempPar_dwtcAvarmean', 'target']]


training_dataframe=pd.read_excel('imputed_Siena_new_other_features_selected_features.xlsx')
training_dataframe=training_dataframe.dropna()
x_train=training_dataframe.drop(["target"],axis=1)
y_train=training_dataframe.target


df=df.dropna()
hl = (30,)
epochs = 100
alpha= 0.001
randomSeed = 42


targetName = 'target'
x_test = df.drop([targetName], axis=1)
y_test = df[targetName]

# Examining and replacing missing values with imputer function using median option.
imp = impute.SimpleImputer(strategy='median')
imp.fit(x_test)
x_test = imp.transform(x_test)

# normalization
#Xscaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))
# yscaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))
#X = Xscaler.fit_transform(X)
# y = yscaler.fit_transform(y.reshape(-1, 1)).ravel()
#x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.3, random_state=randomSeed)

# initializing all the model objects with default parameters
model_1 = LogisticRegression(max_iter=10000,solver='sag')
model_2 = RandomForestClassifier()
model_3 = MLPClassifier(hidden_layer_sizes=hl, solver='sgd',
                    activation='logistic', tol=0.0000001, learning_rate='constant',
                    learning_rate_init=0.01, shuffle=False, max_iter=epochs,
                    random_state=randomSeed, alpha=alpha, validation_fraction=0.42, warm_start=True)

# Making the final model using voting classifier
final_model = VotingClassifier(estimators=[('lr', model_1), ('xgb', model_2), ('rf', model_3)], voting='soft')

# training all the model on the train dataset
final_model.fit(x_train, y_train)

# predicting the output on the test dataset
Y_pred = final_model.predict(x_test)
#print('final pred', Y_pred)
# printing log loss between actual and predicted value
#print('loss\n', log_loss(y_test, pred_final))


print ("Classification accuracy = %f" % metrics.accuracy_score(y_test, Y_pred))
print("Cross validation scores")
cross_scores=cross_val_score(final_model,x_test,y_test)
print('Cross Validation Score', np.max(cross_scores))

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, plot_confusion_matrix
plot_confusion_matrix(final_model, x_test, y_test)
plt.show()

import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
# importing utility modules
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import log_loss
# importing machine learning models for prediction
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression
# importing voting classifier
from sklearn.ensemble import VotingClassifier
import numpy as np
import pandas as pd
from sklearn.feature_selection import mutual_info_classif
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import SelectPercentile
from sklearn.datasets import make_classification
import numpy
import numpy as np
import csv
import warnings
from sklearn.metrics import plot_confusion_matrix
import seaborn as sns
import pandas as pd
import sklearn.tree as tree
import sklearn.impute as impute
import sklearn.model_selection as modelsel
import sklearn.metrics as metrics
from sklearn.neural_network import MLPRegressor
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import r2_score
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
import graphviz
from sklearn.model_selection import cross_val_score
import matplotlib.pylab as plt
import matplotlib.pyplot as plt
import pydotplus
import collections

from sklearn.impute import SimpleImputer



#dirPath = '/Users/rubel/Documents/ECE5424/project/python_code/'
#fileName = 'grouped_complete_MIT.xlsx'
fileName = 'grouped_complete_Siena.xlsx'
filename_RT='grouped_complete_Siena_RT.xlsx'
"""
# MIT DataFrame
df = pd.read_excel(fileName, usecols=['T7-P7_variance', 't7-p7_dwtcavar', 'p7-o1_dwtcavar', 'f7-t7_dwtcarms',
                                                't7-p7_dwtcarms', 'F3-C3_ISI', 'C3-P3_ISI', 'P3-O1_ISI', 'CZ-PZ_ISI',
                                                'F7-T7_Theta', 'F7-T7_Alpha', 'T7-P7_Theta', 'T7-P7_Alpha',
                                                'P7-O1_Theta', 'P7-O1_Alpha', 'TempPar_Thetamed', 'TempPar_Thetamean',
                                                'TempPar_Alphamed', 'TempPar_Alphamean', 'CentPar_ISImed',
                                                'CentPar_ISImean', 'TempPar_dwtcArmsmed', 'TempPar_dwtcArmsmean',
                                                'TempPar_dwtcAvarmed', 'P8-O2_ZC','FP1-F7_ complexity','F4-C4_ZC',
                                                'F8-T8_ZC', 'p8-o2_dwtcdvar','fp1-f3_dwtcdent','f8-t8_dwtcdent',
                                                'T8-P8_ complexity','f3-c3_dwtcdent','fz-cz_dwtcdrms','FP2-F8_ZC',
                                                'p4-o2_dwtcaent','FrontTemp_variancemed','ParOcc_Betamed','ParOcc_Thetamed',
                                                'FrontTemp_variancemean','target'])
"""

# Siena DataFrame
dataFrame = pd.read_excel("grouped_complete_Siena.xlsx", usecols=['C3_variance', 'P3_variance', 'T5_variance',
       'CP5_variance', 'F9_variance', 'FP2_variance', 'F4_variance',
       'C4_variance', 'O2_variance', 'T4_variance', 'T6_variance',
       'FC2_variance', 'FC6_variance', 'CP2_variance', 'CP6_variance',
       'f7_dwtcdrms', 'f9_dwtcdrms', 'fc6_dwtcdrms', 'T5_avg', 'Cp1_avg',
       'T6_avg', 'Frontal_variancemed', 'Central_variancemed',
       'Occipital_variancemed', 'Occipital_variancemean',
       'Temporal_variancemed', 'Temporal_variancemean',
       'FrontCent_variancemed', 'FrontCent_variancemean',
       'CentPar_variancemed', 'CentPar_variancemean', 'Temporal_avgmed',
       'Temporal_avgmean', 'FrontCent_avgmed', 'FrontCent_avgmean',
       'Frontal_dwtcDrmsmed', 'target'])


dataFrame=dataFrame.dropna()
y=dataFrame.target
#print(y)
X=dataFrame.drop(["target"],axis=1)



#X = X.fillna(X.median())



medianimputer = SimpleImputer(missing_values=np.nan, strategy='median') 
X=medianimputer.fit_transform(X)
X=pd.DataFrame(X)


dataFrame=pd.concat([X,y],axis=1)

dataFrame.to_excel("imputed_Siena_new_other_features_selected_features.xlsx")